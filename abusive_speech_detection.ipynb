{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abusive-speech-detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFnRfASj2sDCBeKQBAqeoe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hate-speech-classification/abusive-level-classification/blob/main/abusive_speech_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLBHplZdXhe_",
        "outputId": "a16c597e-d79d-4036-9102-a5e30737ee85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Init\n",
        "\"\"\"\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import gensim\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Read data from csv (url from github)\n",
        "\"\"\"\n",
        "url_train_data = 'https://raw.githubusercontent.com/amandacurry/convabuse/main/2_splits/ConvAbuseEMNLPtrain.csv'\n",
        "df = pd.read_csv(url_train_data)\n",
        "\n",
        "\"\"\"\n",
        "Create new column labels\n",
        "\"\"\"\n",
        "def categorise(row):\n",
        "  if row['Annotator1_is_abuse.1'] == '1':\n",
        "    return 'Not abusive'\n",
        "  elif row['Annotator1_is_abuse.0'] == '1':\n",
        "    return \"Ambiguous\"\n",
        "  elif row['Annotator1_is_abuse.-1'] == '1':\n",
        "    return \"Mildly abusive\"\n",
        "  elif row['Annotator1_is_abuse.-2'] == '1':\n",
        "    return \"Strongly abusive\"\n",
        "  elif row['Annotator1_is_abuse.-3'] == '1':\n",
        "    return \"Very strongly abusive\"\n",
        "\n",
        "my_tags = ['Not abusive', 'Ambiguous', 'Midly abusive', 'Strongly abusive', 'Very strongly abusive']\n",
        "df['abusive_level'] = df.apply(lambda row: categorise(row), axis=1) \n",
        "df = df[pd.notnull(df['abusive_level'])]\n",
        "# df.tail(10)"
      ],
      "metadata": {
        "id": "fDjqnPHcXs4I"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Clean text (user column)\n",
        "\"\"\"\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text\n",
        "    \n",
        "df['user'] = df['user'].apply(clean_text)\n",
        "data = df[['user','abusive_level']]\n",
        "X = data.user\n",
        "Y = data.abusive_level\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)\n",
        "# data.tail(10)"
      ],
      "metadata": {
        "id": "RuBvcSA-e3YU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Naive Bayes Classifier \n",
        "Idea: text is categorized based on TF*IDF (term frequency * inverse data frequency)\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# %%time\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=my_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-jOeX_2tncl",
        "outputId": "02e56252-4f53-4203-b2a2-473d83e8633c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.786096256684492\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "          Not abusive       0.00      0.00      0.00         6\n",
            "            Ambiguous       0.00      0.00      0.00        16\n",
            "        Midly abusive       0.79      1.00      0.88       144\n",
            "     Strongly abusive       0.60      0.20      0.30        15\n",
            "Very strongly abusive       0.00      0.00      0.00         6\n",
            "\n",
            "             accuracy                           0.79       187\n",
            "            macro avg       0.28      0.24      0.24       187\n",
            "         weighted avg       0.66      0.79      0.70       187\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Linear Support Vector Machine\n",
        "Idea: text is categorized based on TF*IDF (term frequency * inverse data frequency)\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "# %%time\n",
        "\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=my_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xejOTK2HwSPe",
        "outputId": "dbad97eb-ba54-4287-aa62-a83e1a01b319"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.8021390374331551\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "          Not abusive       0.00      0.00      0.00         6\n",
            "            Ambiguous       0.33      0.12      0.18        16\n",
            "        Midly abusive       0.85      0.97      0.90       144\n",
            "     Strongly abusive       0.57      0.53      0.55        15\n",
            "Very strongly abusive       0.50      0.17      0.25         6\n",
            "\n",
            "             accuracy                           0.80       187\n",
            "            macro avg       0.45      0.36      0.38       187\n",
            "         weighted avg       0.74      0.80      0.76       187\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Logistic Regression\n",
        "Idea: text is categorized based on TF*IDF (term frequency * inverse data frequency)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# %%time\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=my_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsjGQf4vwXvk",
        "outputId": "91b89c43-5b18-43ee-9862-959636246e98"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.7593582887700535\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "          Not abusive       0.00      0.00      0.00         6\n",
            "            Ambiguous       0.19      0.19      0.19        16\n",
            "        Midly abusive       0.86      0.93      0.89       144\n",
            "     Strongly abusive       0.50      0.27      0.35        15\n",
            "Very strongly abusive       0.33      0.17      0.22         6\n",
            "\n",
            "             accuracy                           0.76       187\n",
            "            macro avg       0.38      0.31      0.33       187\n",
            "         weighted avg       0.73      0.76      0.74       187\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LqfL9iWTwegX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}